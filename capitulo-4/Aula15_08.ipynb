{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOel8Mcl06AXKOzLNzhyGHJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s1fW72SEG77m","executionInfo":{"status":"ok","timestamp":1692101529805,"user_tz":180,"elapsed":4,"user":{"displayName":"Sílvio Cesar Silva Oliveira","userId":"16644722732914378294"}},"outputId":"8bf3bce5-4a99-4f9e-f70b-340f1c91e5a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Este um texto com caracteres especiais \n"]}],"source":["import re\n","\n","texto = \"Este é um texto com @caracteres! especiais #\\$\"\n","# remover caracteres especiais\n","texto_sem_especiais = re.sub('[^A-Za-z0-9]+', ' ', texto)\n","print(texto_sem_especiais) # Saída: Este é um texto com caracteres especiais"]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","\n","texto = \"\"\"Este é um texto de exemplo para tokenização.\n","Ele contém várias frases diferentes.\"\"\"\n","# dividir o texto em frases\n","frases = nltk.sent_tokenize(texto)\n","# dividir o texto em palavras\n","palavras = nltk.word_tokenize(texto)\n","print(frases)\n","# Saída: ['Este é um texto de exemplo para tokenização.',\n","# 'Ele contém várias frases diferentes.']\n","print(palavras)\n","# Saída: ['Este', 'é', 'um', 'texto', 'de', 'exemplo', 'para', 'tokenização', '.',\n","# 'Ele', 'contém', 'várias', 'frases', 'diferentes', '.']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e62RWXNRHfXY","executionInfo":{"status":"ok","timestamp":1692101736373,"user_tz":180,"elapsed":1125,"user":{"displayName":"Sílvio Cesar Silva Oliveira","userId":"16644722732914378294"}},"outputId":"479ee229-d163-4b03-d1fe-ac2c1a12e97a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["['Este é um texto de exemplo para tokenização.', 'Ele contém várias frases diferentes.']\n","['Este', 'é', 'um', 'texto', 'de', 'exemplo', 'para', 'tokenização', '.', 'Ele', 'contém', 'várias', 'frases', 'diferentes', '.']\n"]}]},{"cell_type":"code","source":["from textblob import TextBlob\n","texto = \"Brazil is not an amazing country!\"\n","blob = TextBlob(texto)\n","sentimento = blob.sentiment.polarity\n","if sentimento > 0:\n","  print(\"O texto tem uma conotação positiva.\")\n","elif sentimento < 0:\n","  print(\"O texto tem uma conotação negativa.\")\n","else:\n"," print(\"O texto tem uma conotação neutra.\")\n"," # Saída: O texto tem uma conotação positiva.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwCTLQcIIPx_","executionInfo":{"status":"ok","timestamp":1692102100748,"user_tz":180,"elapsed":5,"user":{"displayName":"Sílvio Cesar Silva Oliveira","userId":"16644722732914378294"}},"outputId":"876ab8c9-0eed-4de2-8b73-11b1d9e17471"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["O texto tem uma conotação positiva.\n"]}]}]}